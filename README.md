# SIGN-LANGUAGE-TRANSLATOR-FOR-ALPHABETIC-RECOGNITION
This project focuses on developing a real-time sign
language translator for alphabet recognition using Convolutional Neural Networks (CNN). The
system captures hand gestures through a camera, preprocesses the input, and employs CNNs for
gesture recognition, converting them into text and speech outputs for effective communication.
The implementation includes capturing real-time gestures, preprocessing video frames to extract
essential features, and utilizing a CNN model trained on a comprehensive dataset for accurate
prediction.
